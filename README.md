# Multiclass Logistic Regression

In this notebook, we delve into the realm of multiclass logistic regression. Unlike binary logistic regression, which classifies between two classes, multiclass logistic regression extends the capability to handle multiple classes.

## Key Objectives:

1. **Model Training**: Implementing logistic regression for multiple classes using a one-vs-all (one-vs-rest) approach.
2. **Accuracy Evaluation**: Assessing the accuracy of the trained model on a validation dataset.
3. **Confusion Matrix Analysis**: Visualizing the performance of the model through a confusion matrix, which provides insights into correct and incorrect classifications.

## Core Concepts Explored:

- **Softmax Function**: Utilized to convert raw scores into class probabilities.
- **Cross-Entropy Loss**: A common loss function for multiclass classification problems.
- **Gradient Descent**: The optimization algorithm used to update model parameters.

## Evaluation Metrics:

- **Accuracy**: The percentage of correctly classified instances.
- **Precision**: The proportion of correctly predicted positive instances among all predicted positives.
- **Recall (Sensitivity)**: The proportion of correctly predicted positive instances among all actual positives.
- **F1 Score**: The harmonic mean of precision and recall, offering a balance between the two.

Through this exploration, we aim to build a solid understanding of the principles behind multiclass logistic regression, its implementation, and the evaluation metrics essential for assessing model performance.

